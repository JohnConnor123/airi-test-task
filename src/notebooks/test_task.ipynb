{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cc9c83-056f-42bb-bcf2-183c2bea20fa",
   "metadata": {},
   "source": [
    "# Protein stability ∆∆G prediction\n",
    "Predicting protein stability changes due to mutations is a critical task in bioinformatics, with applications in drug design, protein engineering, and understanding disease mechanisms. In this task, you are provided with feature representations of protein pairs (wild type and mutant type) and are required to predict the stability change (∆∆G) resulting from the mutations. Only single substitution mutations are considered. Single substitution mutation is when a single amino acid in the protein is changed to another one.\n",
    "\n",
    "## Provided Data\n",
    "You will work with two datasets. \n",
    "- A subset of [PROSTATA](https://www.biorxiv.org/content/10.1101/2022.12.25.521875v1) dataset. Contains features calculated with [OpenFold](https://github.com/aqlaboratory/openfold) for 2375 mutations. This dataset will be used as training dataset. Target ∆∆G scores are provided.\n",
    "- A test dataset that does not contain any proteins homologous to the training set.  Contains features calculated with [OpenFold](https://github.com/aqlaboratory/openfold) for 907 mutations. This dataset will be used as test dataset. **Target ∆∆G scores are not provided.** In this notebook, ∆∆G scores are actually known to show how the metrics can be calculated.\n",
    "\n",
    "## Baseline model\n",
    "In this notebook, we provide the code that preprocesses data, creates an `MLP` model and trains on mutations from PROSTATA. It also calculates the metrics on test dataset. Note that target scores will not be available.\n",
    "\n",
    "## Submission Format\n",
    "Your submission should include:\n",
    "\n",
    "- Reproducible code that trains the final model.\n",
    "- Predictions CSV: A CSV file containing your predicted ∆∆G values for the test dataset.\n",
    "- Technical Report: A detailed report explaining your approach, including:\n",
    "    + Model selection and training process.\n",
    "    + Evaluation results and analysis.\n",
    "    + Any challenges faced and how they were addressed.\n",
    "    + Possible improvements and future work.\n",
    "\n",
    "## Requirements\n",
    "- `python>=3.9`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `torch`\n",
    "- `torchvision`\n",
    "- `scipy`\n",
    "- `sklearn`\n",
    "\n",
    "## Conclusion\n",
    "In this task, you are expected to leverage your machine learning skills to predict protein stability changes. We encourage you to explore different models, feature engineering techniques, and hyperparameter tuning to improve your predictions. Your technical report should reflect your thought process, experimentation, and insights gained during the task.\n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea1aae-5e08-4129-825d-2738779a590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62b6b7-70e0-4699-95b6-617f46acedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9dc885-f44e-4108-a265-b6d81742be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protein_task import ProteinTask, get_protein_task, get_feature_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37c813-d457-430a-81a0-4208c5f7f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906b041-2b2a-4bb4-9252-1eeddd169866",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1aeb8-d4ba-4e81-91b0-ac7259e68f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/prostata_filtered.csv\")\n",
    "target = torch.tensor(df_train[\"ddg\"], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8784e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c7c23-a610-4241-85d4-5507dda07e4a",
   "metadata": {},
   "source": [
    "Load protein features. Protein is represented as a ```ProteinTask``` class object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21a46f-27af-4fbe-bc3c-ff5cc487075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tasks = \"../data/prostata_test_task\"\n",
    "all_tasks = []\n",
    "\n",
    "for idx in range(len(df_train)):\n",
    "    task = get_protein_task(df_train, idx=idx, path=path_to_tasks)\n",
    "    all_tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d997572",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63d30d-ebb7-4482-8faa-4ff768319cc4",
   "metadata": {},
   "source": [
    "Load test protein features. **Note that DDG for test dataset is unavailable and only given here and below as an example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c2aaf-da36-426b-8767-5a5525e4d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ssym = pd.read_csv(\"../data/ssym.csv\")\n",
    "df_test_s669 = pd.read_csv(\"../data/s669.csv\")\n",
    "df_test = pd.concat((df_test_ssym, df_test_s669), axis=\"rows\", ignore_index=True)\n",
    "\n",
    "# test_target = torch.tensor(df_test[\"ddg\"], dtype=torch.float32) # test DDG not available\n",
    "test_target = torch.zeros(df_test.shape[0], dtype=torch.float32) # Note that this is FAKE target\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f94fb4-1022-4e2b-82ab-aa0cb3f16082",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_tasks = []\n",
    "path_to_test_tasks = {\n",
    "    \"ssym\": \"../data/ssym_test_task\",\n",
    "    \"s669\": \"../data/s669_test_task\"\n",
    "}\n",
    "\n",
    "for idx in range(len(df_test)):\n",
    "    source = df_test.iloc[idx][\"source\"]\n",
    "    task = get_protein_task(df_test, idx=idx, path=path_to_test_tasks[source])\n",
    "    test_all_tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_all_tasks[0].__dict__.keys())\n",
    "\n",
    "print()\n",
    "print(test_all_tasks[0].__dict__['task'].keys())\n",
    "print(test_all_tasks[0].__dict__['protein_job'].keys())\n",
    "print(test_all_tasks[0].__dict__['protein_of'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a9edd-5add-480e-891c-3f5cabcc46b0",
   "metadata": {},
   "source": [
    "`ProteinTask` object has three fields:\n",
    "- `task` stores general information about the protein: path to the `pdb` file, list of mutations, and the numbering of residues in the protein (`obs_positions`). Mutations are stored as dictionaries : `{(<wild type amino acid>, <position of mutation>, <chain id>): <mutant type amino acid>}`. Please note that numbering of residues in proteins does not always start with `0` so the correct position of the mutation does not correspond to `<position of mutation>` in general.\n",
    "- `protein_of` contains features precomputed with OpenFold for both wild type and mutant type proteins as well as `pd.DataFrame` representations of proteins. The features are represented as dictionaries: `{\"<amino acid>_<chain_id>_<position>\": features_dict}`, where `features_dict` is itself a dictionary containing all OpenFold outputs for a specific residue:\n",
    "```\n",
    "'msa' tensor, shape=(256,)\n",
    "'pair' tensor, shape=(128,)\n",
    "'lddt_logits' tensor, shape=(50,)\n",
    "'distogram_logits' tensor, shape=(64,)\n",
    "'aligned_confidence_probs' tensor, shape=(64,)\n",
    "'predicted_aligned_error' tensor, shape=(1,)\n",
    "'plddt' tensor, shape=(1,)\n",
    "'single' tensor, shape=(384,)\n",
    "'tm_logits' tensor, shape=(64,)\n",
    "```\n",
    " Note that `pair`, `distogram_logits` and `aligned_confidence_probs` are calculated for each pair of residues in the protein, so the full tensors have the shape of `[num_residues x num_residues x embedding_dim]`. However, we are limited in terms of the size of the dataset, so only the diagonal elements are taken from full tensors. For example, `pair` representations for residue `idx` is calculated as the corresponding diagonal vector of the full pair representation tensor: `pair = pair_initial[idx, idx, :]`. Refer to [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) paper and [OpenFold](https://github.com/aqlaboratory/openfold) for more information.\n",
    "- `protein_job` contains `pd.DataFrame` representations for both wild type and mutant type proteins as well as a mapping from numbering of residues in the protein to their corresponding index in the features tensor. The mapping `obs_positions` is a dictionary `{<amino acid>_<chain_id>_<position>: <feature index>}`.\n",
    "\n",
    "Next, we demonstrate how to use the `obs_positions` mapping to get features of mutated amino acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e72e8f-f468-40fa-b875-b05867bfbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task = all_tasks[1234]\n",
    "mutation = example_task.task['mutants']\n",
    "print(\"all_tasks[1234].task:\")\n",
    "pprint(all_tasks[1234].task)\n",
    "\n",
    "# there is only one mutation for proteins in PROSTATA so take the first element of the dictionary\n",
    "mutation_key, _ = next(iter(mutation.items()))\n",
    "res_name, position, chain_id = mutation_key\n",
    "\n",
    "# translate mutation key to feature index: \"<amino acid>_<chain_id>_<position>\"\n",
    "residue_name = '_'.join((res_name, chain_id, str(position)))\n",
    "print(\"\\nresidue_name:\", residue_name)\n",
    "feature_index = example_task.protein_job['protein_wt']['obs_positions'][residue_name]\n",
    "print(\"feature_index:\", feature_index)\n",
    "\n",
    "# feature index of mutated aminoacid is the same; the name of the amino acid in the mapping is not changed\n",
    "assert feature_index == example_task.protein_job['protein_mt']['obs_positions'][residue_name]\n",
    "\n",
    "# get OpenFold features corresponding to the mutated amino acid of the wild type and mutant type protein\n",
    "feature_tensor = get_feature_tensor(example_task, feature_names=[\"pair\", \"lddt_logits\", \"plddt\"]) # feel free to experiment with different features :)\n",
    "features = torch.cat((feature_tensor['wt'][feature_index], feature_tensor['mt'][feature_index]), dim=0)\n",
    "\n",
    "print(\"features.shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task.protein_job['protein_wt']['obs_positions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f86f2-9df0-4a94-a4ac-cc71ad37c48e",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d7a16-4e1c-49f2-ad6a-f9dde8dad7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a5757-b0ea-44ec-b8e1-c8b045e6f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for task in all_tasks:\n",
    "    mutation = task.task['mutants']\n",
    "    mutation_key, _ = next(iter(mutation.items()))\n",
    "    res_name, position, chain_id = mutation_key\n",
    "    residue_name = '_'.join((res_name, chain_id, str(position)))\n",
    "    feature_index = task.protein_job['protein_wt']['obs_positions'][residue_name]\n",
    "    feature_tensor = get_feature_tensor(task, feature_names=[\"pair\", \"lddt_logits\", \"plddt\"]) \n",
    "    features.append(torch.cat((feature_tensor['wt'][feature_index], feature_tensor['mt'][feature_index]), dim=0))\n",
    "\n",
    "features = torch.stack(features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, val_features, train_target, val_target = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac718e47-db9a-4a20-94fc-287fa6902be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = []\n",
    "for task in test_all_tasks:\n",
    "    mutation = task.task['mutants']\n",
    "    mutation_key, _ = next(iter(mutation.items()))\n",
    "    res_name, position, chain_id = mutation_key\n",
    "    residue_name = '_'.join((res_name, chain_id, str(position)))\n",
    "    feature_index = task.protein_job['protein_wt']['obs_positions'][residue_name]\n",
    "    feature_tensor = get_feature_tensor(task, feature_names=[\"pair\", \"lddt_logits\", \"plddt\"]) \n",
    "    features_test.append(torch.cat((feature_tensor['wt'][feature_index], feature_tensor['mt'][feature_index]), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f54ef3-f9f8-4675-b765-eaae2c40bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_features, train_target[:, None])\n",
    "val_dataset = TensorDataset(val_features, val_target[:, None])\n",
    "all_dataset = TensorDataset(features, target[:, None])\n",
    "test_dataset = TensorDataset(torch.stack(features_test, dim=0), test_target[:, None])\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=True)\n",
    "all_dataloader = DataLoader(dataset=all_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340526ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = int(len(train_dataset) * torch.rand(1))\n",
    "train_dataset[ind][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83018290",
   "metadata": {},
   "source": [
    "Y_pred $\\in$ $R^1$, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43da23-4966-4836-98cc-68d128bab112",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1bf929-40c9-4c1c-8e34-df81f4aee432",
   "metadata": {},
   "source": [
    "Create a model. We chose a simple MLP as a baseline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502bbd3-2d62-4a21-9eab-891449ee0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c3966-8f9b-4204-86e2-2bffcc1c5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPHead(MLP):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        dim_hidden,\n",
    "        num_layers=3,\n",
    "        norm_layer=None,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        hidden_channels = [dim_hidden] * (num_layers - 1) + [1]\n",
    "        super(MLPHead, self).__init__(\n",
    "            in_channels,\n",
    "            hidden_channels,\n",
    "            inplace=False,\n",
    "            norm_layer=norm_layer,\n",
    "            dropout=dropout\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d321e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X: {len(features)}x{len(features[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c17795-a7d2-4847-b910-eb7bf345be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPHead(in_channels=features[0].size(0), dim_hidden=128, dropout=0.5, norm_layer=torch.nn.BatchNorm1d).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44d9c3-a45d-4a91-aeee-7b5633a91ce9",
   "metadata": {},
   "source": [
    "### Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa781ca-4a81-4425-9d8a-b4e8d7e65039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d67857-252b-4e42-ac66-646b22a332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c9d53-9e4c-4c8e-b41c-88a783d7f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c09b93-a9f7-4da4-a0ac-7f1e48753d44",
   "metadata": {},
   "source": [
    "### Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39797884-7cab-42bf-a4ae-76ebbf50e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b29dfc-7247-4157-863b-0c5ae445dc57",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    outputs = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            inputs, y = data\n",
    "            inputs = inputs.to(DEVICE)\n",
    "        \n",
    "            # Make predictions for this batch\n",
    "            outputs.append(model(inputs))\n",
    "            y_true.append(y)\n",
    "    outputs = torch.cat(outputs, dim=0).cpu()\n",
    "    y_true = torch.cat(y_true, dim=0).cpu()\n",
    "    return outputs.squeeze(), y_true.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fc0cc-39a1-4461-86d9-8edb3ebadf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test():\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(DEVICE)\n",
    "        \n",
    "            # Make predictions for this batch\n",
    "            outputs.append(model(inputs))\n",
    "    outputs = torch.cat(outputs, dim=0).cpu()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea33fe-2a94-4d63-99b6-75bfa9a62536",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "`compute_metrics` calculates various metrics. We consider three types of metrics. \n",
    "\n",
    "Regression metrics.\n",
    "- **R2**\n",
    "- **Spearman correlation coefficient**\n",
    "- **Pearson correlation coefficient**\n",
    "- **RMSE**\n",
    "\n",
    "Classification metrics. The mutation is considered stabilizing (label=+1) if the DDG is less than -0.5. Otherwise, the mutation is considered destabilizing (label=-1).\n",
    "- **AUC score**\n",
    "- **Accuracy**\n",
    "- **Matthews correlation coefficient**\n",
    "\n",
    "We consider how well the model performs on stabilizing mutations only:\n",
    "- **DetPr**. Precision of the model among 30 most stabilizing mutations\n",
    "- **StabSpearman**. Spearman correlation coefficient for stabilizing mutations only\n",
    "\n",
    "Additionally, we calculate how well the model ranks the mutations (**nDCG@30**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea7319-923e-484f-bbc6-3b6a167e6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7cb9e-db0c-4844-a374-e43c54f59b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code from https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "EPOCHS = 100\n",
    "metrics_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = predict()    \n",
    "    # Example of how to compute metrics\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    metrics_list.append(metrics)\n",
    "    \n",
    "    if epoch % 10 == 9:\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf33351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea83435-2e12-43a9-b2c1-3e2701cd119c",
   "metadata": {},
   "source": [
    "Lastly, we provide metrics that we calculated on the test set using **real** DDG targets:\n",
    "```\n",
    "'R2': 0.04984921216964722,\n",
    "'RMSE': 1.5236231\n",
    "'Pearson': 0.571105009522608\n",
    "'Spearman': 0.5379472889898176\n",
    "'StabSpearman': 0.47610780612378306\n",
    "'DetPr': 0.8669201520912547\n",
    "'nDCG': 0.921864101605235\n",
    "'MCC': 0.37286990274549875\n",
    "'AUC': 0.749912739965096\n",
    "'ACC': 0.6339581036383682\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c8f08",
   "metadata": {},
   "source": [
    "### TODO: Разобраться с NaN-ами в корреляциях\n",
    "\n",
    "Результат: test_target фейковый, надо сделать доп сплит train на train и val части, чтоб можно было логгировать метрики и сравнивать их"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2187775",
   "metadata": {},
   "source": [
    "### Metrics on val split\n",
    "Обучил модель на 80% датасета:\n",
    "```\n",
    "'R2': -0.1599416771112705,\n",
    "'RMSE': 1.9796233,\n",
    "'Pearson': 0.0030046694493472597,\n",
    "'Spearman': 0.0004074060793166234,\n",
    "'StabSpearman': 0.09012345238369182,\n",
    "'DetPr': 0.5368421052631579,\n",
    "'nDCG': 0.49273661359929855,\n",
    "'MCC': -0.0590705236576487,\n",
    "'AUC': 0.47435525934511735,\n",
    "'ACC': 0.4568421052631579\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f125a5",
   "metadata": {},
   "source": [
    "Кажется я понял в чем причина таких плохих метрик - игрики в dataloader'ах перемешиваются, а массив target нет. После переписывания кода получились такие метрики:\n",
    "```\n",
    "'R2': 0.029641989535255653,\n",
    "'RMSE': 1.8106332,\n",
    "'Pearson': 0.466969494741527,\n",
    "'Spearman': 0.5999362157954573,\n",
    "'StabSpearman': 0.4345694075738714,\n",
    "'DetPr': 0.8807339449541285,\n",
    "'nDCG': 0.8690258021706866,\n",
    "'MCC': 0.33988255813829066,\n",
    "'AUC': 0.7897710808461316,\n",
    "'ACC': 0.6021052631578947\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df0b67",
   "metadata": {},
   "source": [
    "# TODO: Добавить окружение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c7b6c",
   "metadata": {},
   "source": [
    "- Добавил dvc, заверсионировав датасет и убрав с гитхаба тяжелую папку\n",
    "- Добавил poetry\n",
    "- Добавил прекоммиты и настроил их\n",
    "- Добавил поддержку hydra\n",
    "- Пофиксил баги (пример бага ниже):\n",
    "```\n",
    "protein_task.py:106:63: B008 Do not perform function calls in argument defaults.  The call is performed only once at function definition time. All calls to your function will reuse the result of that definition-time function call.  If this is intended, assign the function call to a module-level variable and use that variable as a default value.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d7b14",
   "metadata": {},
   "source": [
    "# TODO: Переписать код полностью, добавить структуру в проект"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512643e",
   "metadata": {},
   "source": [
    "- Добавил структуру\n",
    "- Разбил код на модули и функции внутри их\n",
    "- Улучшил нейминг переменных\n",
    "- Ускорил препроцессинг\n",
    "- Ускорил обучение (было 2сек на эпоху, стало 0.5сек как в этом ноутбуке или даже быстрее))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c323c3",
   "metadata": {},
   "source": [
    "# TODO: Посчитать дисбаланс классов +1 и -1 у label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b740209",
   "metadata": {},
   "source": [
    "# TODO: Почистить данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23fa7e",
   "metadata": {},
   "source": [
    "# TODO: Сделать визуализацию данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bf2e6-7f24-4acb-a34b-959b4d9120c2",
   "metadata": {},
   "source": [
    "As the result of the test task, we expect:\n",
    "- Reproducible code that trains the prediction model.\n",
    "- Predictions for the test dataset.\n",
    "- A detailed technical report on how the problem was approached. The technical report may include data analysis, experiment description, model architecture, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
